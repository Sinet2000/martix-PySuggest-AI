{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Basic Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 1. Import common libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 2. Import PyTorch\n",
    "import torch\n",
    "import torch.nn as nn # Neural network module\n",
    "import torch.optim as optim # Adam or SGD.\n",
    "\n",
    "# Check PyTorch version and if GPU is available\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating a Toy Dataset for Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0        3        1       3\n",
       "1        4        5       5\n",
       "2        2        4       1\n",
       "3        4        3       2\n",
       "4        4        0       4\n",
       "5        1        0       1\n",
       "6        2        2       4\n",
       "7        2        2       2\n",
       "8        2        1       2\n",
       "9        4        3       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's define the number of users, items, and interactions\n",
    "num_users = 5\n",
    "num_items = 6\n",
    "num_interactions = 20\n",
    "\n",
    "# Generate random user-item interactions\n",
    "np.random.seed(42)\n",
    "user_ids = np.random.randint(0, num_users, size=num_interactions)\n",
    "item_ids = np.random.randint(0, num_items, size=num_interactions)\n",
    "\n",
    "# Let's create some synthetic rating or \"interaction\" score\n",
    "ratings = np.random.randint(1, 6, size=num_interactions)  # rating from 1 to 5\n",
    "\n",
    "# Combine into a Pandas DataFrame for clarity\n",
    "df = pd.DataFrame({\n",
    "    'user_id': user_ids,\n",
    "    'item_id': item_ids,\n",
    "    'rating': ratings\n",
    "})\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Simple Matrix Factorization Model (PyTorch)\n",
    "## 3.1 Model Architecture\n",
    "- User Embedding: Maps each user to a latent vector (e.g., 8 dimensions).\n",
    "- Item Embedding: Maps each item to a latent vector (8 dimensions).\n",
    "- We predict the rating by taking the dot product of these two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=8):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # Initialize embeddings for stability\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        # user_ids, item_ids are [batch_size]\n",
    "        user_vectors = self.user_emb(user_ids)\n",
    "        item_vectors = self.item_emb(item_ids)\n",
    "        # Dot product across embedding dim\n",
    "        preds = torch.sum(user_vectors * item_vectors, dim=1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Preparing Data for PyTorch\n",
    "We need tensors for users, items, and ratings. Then we’ll create a minimal DataLoader for batch processing.\n",
    "\n",
    "## 4.1 Convert DataFrame to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame columns to tensors\n",
    "user_ids_tensor = torch.tensor(df['user_id'].values, dtype=torch.long)\n",
    "item_ids_tensor = torch.tensor(df['item_id'].values, dtype=torch.long)\n",
    "ratings_tensor  = torch.tensor(df['rating'].values, dtype=torch.float)\n",
    "\n",
    "# Combine into a TensorDataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(user_ids_tensor, item_ids_tensor, ratings_tensor)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "batch_size = 4\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training Loop\n",
    "## 5.1 Initialize the Model and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorization(num_users=num_users, num_items=num_items, embedding_dim=8)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. The Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 10.6472\n",
      "Epoch [2/5], Loss: 10.6096\n",
      "Epoch [3/5], Loss: 10.5049\n",
      "Epoch [4/5], Loss: 10.3094\n",
      "Epoch [5/5], Loss: 9.9749\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for users, items, ratings in loader:\n",
    "        # Move data to GPU if available\n",
    "        users = users.to(device)\n",
    "        items = items.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # 1. Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 2. Forward pass\n",
    "        preds = model(users, items)\n",
    "\n",
    "        # 3. Compute the loss\n",
    "        loss = criterion(preds, ratings)\n",
    "\n",
    "        # 4. Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(loader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step:\n",
    "\n",
    "- Zero gradients to avoid accumulation from previous batches.\n",
    "- Forward pass: Model predicts ratings from user/item embeddings.\n",
    "- Calculate loss: MSELoss between predicted and actual ratings.\n",
    "- Backward pass: Compute gradients using loss.backward().\n",
    "- Step optimizer: Update parameters according to the gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Quick Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE on entire dataset: 9.6940\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Let's evaluate predictions on the entire dataset\n",
    "    preds = model(\n",
    "        user_ids_tensor.to(device),\n",
    "        item_ids_tensor.to(device)\n",
    "    )\n",
    "    mse = criterion(preds, ratings_tensor.to(device)).item()\n",
    "    print(f\"Final MSE on entire dataset: {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What’s Next?\n",
    "Proper Train/Test Split\n",
    "\n",
    "Evaluating on the entire dataset (the same one you trained on) does not give a true measure of generalization.\n",
    "You need to split your data into training and test sets (and possibly a validation set):\n",
    "python\n",
    "Copy\n",
    "# Example split (using scikit-learn):\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then create separate train_loader and test_loader\n",
    "Train on the train set, then evaluate on the test set to see how well your model generalizes to unseen data.\n",
    "Tune Hyperparameters\n",
    "\n",
    "Increase embedding dimension: Instead of embedding_dim=8, try 16, 32, etc.\n",
    "Adjust learning rate: Start with 1e-3 or 1e-4.\n",
    "Change the optimizer: e.g., Adam vs. SGD.\n",
    "Increase epochs and watch for overfitting or underfitting.\n",
    "Use a More Meaningful Dataset\n",
    "\n",
    "If you’re using real user interaction data (with many more users and items), you may see different MSE behaviors.\n",
    "Real recommendation tasks often also measure ranking metrics (Precision@k, Recall@k, NDCG).\n",
    "Implement a Ranking Evaluation\n",
    "\n",
    "For many recommendation systems, the ranking of items (rather than absolute rating predictions) is the key.\n",
    "Consider implementing metrics like Precision@k, Recall@k, or NDCG.\n",
    "This usually involves generating top-N item predictions per user and comparing them to the user’s actual next interactions.\n",
    "Regularization\n",
    "\n",
    "If MSE is high or if the model is overfitting, you may want to add weight decay or embedding regularization.\n",
    "E.g., in PyTorch’s Adam optimizer:\n",
    "python\n",
    "Copy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "Try a More Complex Model\n",
    "\n",
    "A simple matrix factorization is a good starting point.\n",
    "Next steps could include a neural network (MLP) that uses user and item embeddings plus additional features (like text embeddings from product descriptions or user demographic info)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a rating prediction context (like the toy example we used), the model’s “result” is a predicted rating for each (user, item) pair. However, in a recommendation system, you often use those predicted ratings to rank items and provide the Top-N recommended items for each user.\n",
    "\n",
    "In other words, once your matrix factorization model is trained:\n",
    "\n",
    "You can input a user ID and one (or many) item IDs.\n",
    "The model outputs a single rating score or relevance score for each user–item combination.\n",
    "From there, you typically:\n",
    "\n",
    "Generate predictions for all items (or a subset) for a specific user.\n",
    "Sort the items by the predicted score (descending).\n",
    "Select the top-N as the “best recommended” items.\n",
    "Example: Getting Top-3 Items for a Given User\n",
    "Below is a quick illustration of how you might produce a “top-3” recommendation list once your model is trained. Suppose we want recommendations for a user with ID u. We’ll:\n",
    "\n",
    "Create a list of all item IDs.\n",
    "Predict the scores for (u, item_i).\n",
    "Sort the items by the prediction.\n",
    "Return the top 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
